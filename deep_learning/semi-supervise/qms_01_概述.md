# 半监督学习简介

> 《An Overview of Deep Semi-Supervised Learning》

在传统的监督学习中，每一个training data都是由data和label构成的，但是一般情况下，只能获取大量的数据，标注需要大量成本。

半监督学习（Semi-supervised learning，SSL）的定义为：有标注的数据占比非常的小（只有1-10%）。半监督学习的目标是利用未标记的数据得到更好表现的模型。未标记的数据集可以为我们提供关于数据真实分布的一些额外信息

## 常见方法

**一致性回归**Consistency Regularization (a.k.a Consistency Training)基于假设：假设一个很小的现实扰动被加入这个没有被标记的数据中，这个数据的分类不会改变。可以训练模型对给定的未标记示例及其扰动版本进行一致的预测

**代理标签方法**Proxy-label Methods：用已经标记的训练集，基于一些启发式的方法来标注未标记的训练集，然后来生成一些额外的训练用例

> 一致性训练也可以被视为一种代理标签方法，有一个细微的差别，
>
> - 代理标签方法将伪标签视为真实标签并计算交叉熵损失 $$\text{Loss}=\text{CrossEntropy}(\text{pred-label}, \text{proxy-label})$$
> - 一致性训练不直接使用伪标签，而是强制两个预测一致，即最小化它们的差异$$\text{Loss}=\text{MSE}(p(x), p(x'))$$

**生成模型**Generative Models：类似于监督设置，其中一个任务上的学习特征可以转移到其他下游任务。

> 例如，图像生成模型（如变分自编码器 VAE 或生成对抗网络 GAN）可以从大量的猫和狗的图像数据（包括有标签和无标签数据）中学习数据的分布特征。它能捕捉到图像中关于猫和狗的通用特征，如形状、颜色、纹理等信息。
>
> 通过学习这些特征，生成模型可以将其迁移到监督学习任务中。例如，生成模型学习到猫的耳朵形状、眼睛特征等关键特征，监督学习模型在对新图像分类时，就可以借助这些特征更准确地判断图像中的动物是猫还是狗。

**基于图的方法**Graph-Based Methods：已标记和未标记的数据点可以被视为图的节点，目标是通过利用两个节点和的相似性，将标签从已标记节点传播到未标记节点，这种相似性体现在两个节点之间的边的强度上

除了这些主要类别之外，在**熵最小化**方面也有一些自监督学习的工作。在熵最小化中，我们通过最小化预测的熵来迫使模型做出自信的预测。

## 半监督学习的假设

**平滑性假设**The Smoothness Assumption：如果两个点在高密度区域中（数据分布的概率密度比较大），且这两个点距离很近，那么他们的输出（标签）也会十分的接近。

**聚类假设**The Cluster Assumption：如果两个点在相同的聚类中，那么他们趋向于被分成同一类。

> 聚类假设也可以被视为低密度分离假设low-density separation assumption：决策边界应该位于低密度区域

**流形假定**The Manifold Assumption：高维的数据一般都会处于一个低维的流形中，可以尝试使用未标记数据找到一个低维表示，然后使用标记数据来解决简化后的任务

> 流形可以理解为高维空间中的低维分布，例如三维空间中的数据点，其实分布在一个二维曲面上

## 相关研究方向

### 主动学习

主动学习 Active Learning 中，学习算法被提供一个大型的未标记数据点池，并且能够以交互方式请求对未标记集合中的任何给定示例进行标记。在被动学习中，要标记的示例是从未标记池中随机选择的，主动学习旨在仔细选择要标记的示例，以在尽可能少的请求下实现更高的准确性，从而最小化获取标记数据的成本。这在数据可能丰富但标签稀缺或获取成本高昂的问题中特别受关注。

普遍的主动学习策略比较难构建，但存在许多启发式方法，两种广泛使用的选择标准是信息性和代表性

- 信息性衡量一个未标记的实例在多大程度上有助于减少统计模型的不确定性
- 代表性衡量一个实例在多大程度上有助于表示输入模式的结构

主动学习和半监督学习自然是相关的，因为两者都旨在使用有限数量的数据来改进学习者。有几项工作考虑在不同任务中结合半监督学习和主动学习

### 迁移学习和域适应

迁移学习 Transfer Learning 用于通过转移从相关领域（称为源领域）学到的知识来改进一个在某个领域（称为目标领域）上的学习者。用于训练模型的源领域与用于测试模型的目标领域相关但不同。应用迁移学习以在目标数据上获得更高的准确性

域适应 Domain Adaptation 中目标任务与源任务相同，但域不同。域适应的目标是训练一个能够在不同分布的不同域中进行泛化的学习器，其中源域有已标记的数据。目标域可以全部标注、部分标注或者不标注

> 迁移学习好比源任务是识别卡通动物图片中的动物类别。目标任务是识别真实图片中的车辆类别（如汽车、卡车）。源任务（动物分类）和目标任务（车辆分类）不同，但模型的特征提取能力（如边缘、形状识别）可以迁移。
>
> 域适应源任务 & 目标任务都为识别动物类别（任务相同）。 数据存在差异：源领域是卡通动物图片，目标领域是真实动物图片（分布不同）。型需要消除领域差异（卡通 vs 真实）