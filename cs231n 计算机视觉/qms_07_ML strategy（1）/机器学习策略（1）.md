[TOC]

# 机器学习策略（1）

在尝试优化一个深度学习系统时，通常可以有很多想法可以去试，问题在于，如果做出了错误的选择，完全有可能白费6个月的时间，往错误的方向前进，在6个月之后才意识到这方法根本不管用。

机器学习策略，是搭建和部署大量深度学习产品时学到的经验和教训，一些分析机器学习问题的方法，可以指引朝着最有希望的方向前进。

## 正交化

-------

搭建建立机器学习系统的挑战之一是，可以尝试和改变的东西太多了，而我们希望改变一个细节带来的影响是单一的。这就是正交化的思想。

>   比如，我们不希望改善测试集准确率的同时会降低训练集的准确率。

具体说，如果算法在成本函数上不能很好地拟合训练集，需要一个**旋钮**，这样用来确保可以调整算法，让它很好地拟合训练集，所以这个旋钮是你可能可以训练更大的网络，或者可以切换到更好的优化算法，比如**Adam**优化算法，等等。之后讨论。

相比之下，如果发现算法对开发集的拟合很差，那么应该有另外的独立的旋钮去调试。比如说，算法在训练集上做得很好，但开发集不行，有一组正则化的旋钮可以调节，尝试让系统满足第二个条件。增大训练集可以是另一个可用的旋钮，它可以帮助你的学习算法更好地归纳开发集的规律。

>   复习一下：机器学习中的工作流程是，尝试很多思路，用训练集训练不同的模型，然后使用开发集来评估不同的思路，然后选择一个，然后不断迭代去改善开发集的性能，直到最后可以得到一个满意的成本，然后再用测试集去评估，再做成应用产品。

如果系统在开发集上做的很好，但测试集上做得不好呢？如果是这样，那么需要调的旋钮，可能是更大的开发集。因为如果它在开发集上做的不错，但测试集不行，这可能意味着对开发集过拟合了，需要往回退一步，使用更大的开发集。

最后，如果它在测试集上做得很好，但无法给猫图片应用用户提供良好的体验，这意味着需要回去，改变开发集或成本函数。因为如果根据某个成本函数，系统在测试集上做的很好，但它无法反映你的算法在现实世界中的表现，这意味着要么开发集分布设置不正确，要么成本函数测量的指标不对。

## 评估指标

------

不同算法有很多可以比较的方面，如果有一个单一实数评估指标，就可以综合这许多方面，做一个直观的比较。

### 查准率和查全率

拿查准率（**precision**）和查全率（**recall**）举个例子。

>   查准率：如果分类器$A$有95%的查准率，这意味着分类器说这图有猫的时候，有95%的机会真的是猫。
>
>   查全率：如果分类器$A$查全率是90%，这意味着对于所有的猫图，分类器$A$准确地分辨出了其中的90%。

事实证明，查准率和查全率之间往往需要折衷，两个指标都要顾及到。需要找到一个新的评估指标，能够结合查准率和查全率。在机器学习文献中，结合查准率$P$和查全率$R$的标准方法是所谓的$F_1$分数，公式如下：
$$
F_1=\frac{2}{\frac{1}{P} + \frac{1}{R}}
$$
![](http://www.ai-start.com/dl2017/images/e6c1e59416b60745145b91e87fda5ecf.png)

对于上图这个例子，分类器 $A$ 的$F_1$分数更高，我们认为它更好。

需要注意的是，单一实数评估指标是根据实际需要灵活选择的，不必拘泥于标准方法。

### 错误惩罚

如果对一些分类失败的例子特别反感（比如为爱猫用户错误推送了虐猫照片），可以修改成本函数，公式如下：
$$
J=\frac{1}{\sum{{{w}^{(i)}}}}\sum\limits_{i=1}^{m}{{{w}^{(i)}}L({{\hat y}^{(i)}},{{y}^{(i)}})}
$$
其中，$w^{\left( i \right)}$是一个权重项，其中如果例子$x^{(i)}$不是虐猫图片，则$w^{\left( i \right)} = 1$。如果$x^{(i)}$是虐猫图片，$w^{(i)}$可能就是10甚至100，这样赋予了虐猫图片更大的权重，惩罚权重加大10倍。

>   复习一下，原来的成本函数公式为：
>   $$
>   J=\frac{1}{m}\sum\limits_{i=1}^{m}{L({{\hat y}^{(i)}},{{y}^{(i)}})}
>   $$

## 利用人的表现

------

在很多机器学习任务中，当算法开始往人类水平努力时，进展是很快的。但是过了一段时间，进展和精确度的提升就变得更慢了。然而我们都希望能达到理论最佳性能水平。

![算法精确度的提升趋势](http://www.ai-start.com/dl2017/images/f44d03275801ce5ec97503851eb22ad5.png)

先介绍一个概念，贝叶斯最优错误率一般认为是理论上可能达到的最优错误率，就是说没有任何办法设计出一个$x$到$y$的函数，让它能够超过一定的准确度。从定义上讲，贝叶斯最优错误率肯定比最优秀的人（一群人）的错误率更低。

事实证明，机器学习的进展往往相当快，直到算法超越人类的表现之前一直很快，当算法超越人类的表现时，有时进展会变慢，有两个原因：

1.   人类水平在很多任务中离贝叶斯最优错误率已经不远了，人们非常擅长看图像，分辨里面有没有猫或者听写音频。所以，当超越人类的表现之后也许没有太多的空间继续改善了。
2.   只要算法的表现比人类的表现更差，那么实际上可以使用某些工具来提高性能。一旦超越了人类的表现，这些工具就没那么好用了。

在算法超越人类的表现之前，可以利用人类的表现指导学习。如果人类错误率（近似贝叶斯最优错误率）与训练集错误率相差大，训练集错误率与开发集错误率相差小，在这种情况下，把重点应该放在减少偏差上。比如说：

-   比如使用规模更大的模型。
-   训练更久。
-   使用更好的优化算法，比如说加入**momentum**，**RMSprop**，**Adam**。
-   可以试试寻找更好的新神经网络架构，如循环神经网络和卷积神经网络。
-   改变激活函数，改变层数或者隐藏单位数。
-   可以试试寻找更好的超参数。

如果人类错误率（近似贝叶斯最优错误率）与训练集错误率相差小，训练集错误率与开发集错误率相差大，在这种情况下，应该专注减少方差，比如说：

-   收集更多数据，因为收集更多数据去训练可以帮你更好地推广到系统看不到的开发集数据。
-   可以尝试正则化，包括$L2$正则化，**dropout**正则化或者之前课程中提到的数据增强。
-   同时也可以试用不同的神经网络架构，超参数搜索。
